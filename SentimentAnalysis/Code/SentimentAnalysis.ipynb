{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the NLTK library.\n",
    "# Uncomment and run this line only once to install NLTK.\n",
    "\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources (tokenizer and stopwords).\n",
    "# Uncomment and run these lines once after installing NLTK.\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefull functions\n",
    "\n",
    "# Function to print the results\n",
    "def print_results(conf_matrix):\n",
    "    # Extract values from the confusion matrix\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    # Using f-strings to display metrics with 4 decimal places\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Function to replace suffix \"n't\" with the token \" not\"\n",
    "def handle_negations(tokens):\n",
    "    negation_pattern = [\n",
    "        (r'n\\'t', 'not'),\n",
    "    ]\n",
    "    # Apply replacements\n",
    "    for pattern, replacement in negation_pattern:\n",
    "        tokens = [re.sub(pattern, replacement, token) for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Function to generate n-grams based on terms (tokens)\n",
    "def generate_ngrams(text, n):\n",
    "    n_grams = [text[i:i + n] for i in range(len(text) - n + 1)]\n",
    "    return [' '.join(gram) for gram in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to the positive and negative review folders\n",
    "positive_folder_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\pamak\\\\current_b\\\\IR\\\\HW\\\\PP2\\\\txt_sentoken\\\\pos'\n",
    "negative_folder_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\pamak\\\\current_b\\\\IR\\\\HW\\\\PP2\\\\txt_sentoken\\\\neg'\n",
    "\n",
    "# Function to load reviews from a folder\n",
    "def load_reviews(folder_path, sentiment):\n",
    "    reviews = []\n",
    "    file_names = os.listdir(folder_path)\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            review = file.read()\n",
    "            reviews.append({'filename': file_name, 'review': review, 'sentiment': sentiment})\n",
    "    return reviews\n",
    "\n",
    "# Load positive reviews\n",
    "positive_reviews = load_reviews(positive_folder_path, 'pos')\n",
    "# Load negative reviews\n",
    "negative_reviews = load_reviews(negative_folder_path, 'neg')\n",
    "\n",
    "# Create dataframes\n",
    "df_positive = pd.DataFrame(positive_reviews)\n",
    "df_negative = pd.DataFrame(negative_reviews)\n",
    "\n",
    "# Concatenate dataframes\n",
    "df = pd.concat([df_positive, df_negative], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Multinomial Naive Bayes Performance -----\n",
      "Confusion Matrix:\n",
      "[[809 191]\n",
      " [193 807]]\n",
      "Accuracy: 0.8080\n",
      "Precision: 0.8086\n",
      "Recall: 0.8070\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "\n",
    "# Function to preprocess a text review for Multinomial Naive Bayes\n",
    "def preprocess_review_mnb(review):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(review)\n",
    "    \n",
    "    # Replace suffix \"n't\" with \"not\"\n",
    "    tokens = handle_negations(tokens)\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the 'review' column in the DataFrame\n",
    "df['preprocessed_review'] = df['review'].apply(preprocess_review_mnb)\n",
    "\n",
    "# Separate feature from label\n",
    "X = df['preprocessed_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Vectorize the data (default: Term Occurrences, prune method: percentual)\n",
    "vectorizer = CountVectorizer(min_df=0.039, max_df=0.3)\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Create a KFold object\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Multinomial Naive Bayes classifier\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "# Get predicted labels using cross_val_predict\n",
    "y_pred_cv = cross_val_predict(mnb_classifier, X_vectorized, y, cv=kfold)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred_cv)\n",
    "\n",
    "# Print the results\n",
    "print('----- Multinomial Naive Bayes Performance -----')\n",
    "print_results(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bernulli Naive Bayes Performance -----\n",
      "Confusion Matrix:\n",
      "[[825 175]\n",
      " [290 710]]\n",
      "Accuracy: 0.7675\n",
      "Precision: 0.8023\n",
      "Recall: 0.7100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Bernulli Naive Bayes\n",
    "\n",
    "# Function to preprocess a text review for Bernulli Naive Bayes\n",
    "def preprocess_review_bnb(review):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(review)\n",
    "    \n",
    "    # Replace suffix \"n't\" with \"not\"\n",
    "    # tokens = handle_negations(tokens)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Generate 3-grams based on terms (tokens)\n",
    "    trigrams = generate_ngrams(tokens, 3)\n",
    "    \n",
    "    return ' '.join(tokens + trigrams)\n",
    "\n",
    "# Apply preprocessing to the 'review' column in the DataFrame\n",
    "df['preprocessed_review'] = df['review'].apply(preprocess_review_bnb)\n",
    "\n",
    "# Separate feature from label\n",
    "X = df['preprocessed_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Vectorize the data (Binary Term Occurrences)\n",
    "b_vectorizer = CountVectorizer(binary=True, min_df=0.039, max_df=0.32, ngram_range=(1, 3))\n",
    "X_vectorized = b_vectorizer.fit_transform(X)\n",
    "\n",
    "# Bernulli Naive Bayes classifier\n",
    "bnb_classifier = BernoulliNB()\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_cv = cross_val_predict(bnb_classifier, X_vectorized, y, cv=kfold)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred_cv)\n",
    "\n",
    "# Print the results\n",
    "print('----- Bernulli Naive Bayes Performance -----')\n",
    "print_results(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
